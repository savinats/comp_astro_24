{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd012e94-f8d9-441d-96ee-43ccd36c4eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Loaded datasets!\n",
      "Applying Fourier...\n",
      "Normalizing...\n",
      "Applying Gaussian Filter...\n",
      "Standardizing...\n",
      "Finished Processing!\n",
      "Training SVM with linear kernel...\n",
      "Kernel: linear\n",
      "Train Precision: 0.5624139964615688\n",
      "Dev Precision: 0.5543859649122806\n",
      "Confusion Matrix (Train):\n",
      "[[   0 2226]\n",
      " [   0 2861]]\n",
      "Confusion Matrix (Dev):\n",
      "[[  0 254]\n",
      " [  0 316]]\n",
      "--------------------------------------------------\n",
      "Training SVM with rbf kernel...\n",
      "Kernel: rbf\n",
      "Train Precision: 0.5653296266878475\n",
      "Dev Precision: 0.5543859649122806\n",
      "Confusion Matrix (Train):\n",
      "[[  37 2189]\n",
      " [  14 2847]]\n",
      "Confusion Matrix (Dev):\n",
      "[[  0 254]\n",
      " [  0 316]]\n",
      "--------------------------------------------------\n",
      "Training SVM with poly kernel...\n",
      "Kernel: poly\n",
      "Train Precision: 0.5687980574666127\n",
      "Dev Precision: 0.5597345132743363\n",
      "Confusion Matrix (Train):\n",
      "[[  95 2131]\n",
      " [  50 2811]]\n",
      "Confusion Matrix (Dev):\n",
      "[[ 55 199]\n",
      " [ 63 253]]\n",
      "--------------------------------------------------\n",
      "Evaluation completed and results saved to report_injection_assignment2_taskE.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from scipy import ndimage, fft\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Class to preprocess light flux data\n",
    "class LightFluxProcessor:\n",
    "\n",
    "    def __init__(self, fourier=True, normalize=True, gaussian=True, standardize=True):\n",
    "        self.fourier = fourier\n",
    "        self.normalize = normalize\n",
    "        self.gaussian = gaussian\n",
    "        self.standardize = standardize\n",
    "\n",
    "    def fourier_transform(self, X):\n",
    "        return np.abs(fft.fft(X.values, n=X.size))\n",
    "\n",
    "    def process(self, df_train_x, df_dev_x):\n",
    "        # Apply fourier transform\n",
    "        if self.fourier:\n",
    "            print(\"Applying Fourier...\")\n",
    "            shape_train = df_train_x.shape\n",
    "            shape_dev = df_dev_x.shape\n",
    "            df_train_x = df_train_x.apply(self.fourier_transform, axis=1)\n",
    "            df_dev_x = df_dev_x.apply(self.fourier_transform, axis=1)\n",
    "\n",
    "            df_train_x_build = np.zeros(shape_train)\n",
    "            df_dev_x_build = np.zeros(shape_dev)\n",
    "\n",
    "            for ii, x in enumerate(df_train_x):\n",
    "                df_train_x_build[ii] = x\n",
    "\n",
    "            for ii, x in enumerate(df_dev_x):\n",
    "                df_dev_x_build[ii] = x\n",
    "\n",
    "            df_train_x = pd.DataFrame(df_train_x_build)\n",
    "            df_dev_x = pd.DataFrame(df_dev_x_build)\n",
    "\n",
    "            # Keep first half of data as it is symmetrical after previous steps\n",
    "            df_train_x = df_train_x.iloc[:, :(df_train_x.shape[1] // 2)].values\n",
    "            df_dev_x = df_dev_x.iloc[:, :(df_dev_x.shape[1] // 2)].values\n",
    "\n",
    "        # Normalize\n",
    "        if self.normalize:\n",
    "            print(\"Normalizing...\")\n",
    "            df_train_x = pd.DataFrame(normalize(df_train_x))\n",
    "            df_dev_x = pd.DataFrame(normalize(df_dev_x))\n",
    "\n",
    "        # Gaussian filter to smooth out data\n",
    "        if self.gaussian:\n",
    "            print(\"Applying Gaussian Filter...\")\n",
    "            df_train_x = ndimage.gaussian_filter(df_train_x, sigma=10)\n",
    "            df_dev_x = ndimage.gaussian_filter(df_dev_x, sigma=10)\n",
    "\n",
    "        if self.standardize:\n",
    "            # Standardize X data\n",
    "            print(\"Standardizing...\")\n",
    "            std_scaler = StandardScaler()\n",
    "            df_train_x = std_scaler.fit_transform(df_train_x)\n",
    "            df_dev_x = std_scaler.transform(df_dev_x)\n",
    "\n",
    "        print(\"Finished Processing!\")\n",
    "        return df_train_x, df_dev_x\n",
    "\n",
    "# Helper function to shuffle and split the dataframe\n",
    "def np_X_Y_from_df(df):\n",
    "    df = shuffle(df)\n",
    "    df_X = df.drop(['LABEL'], axis=1)\n",
    "    X = np.array(df_X)\n",
    "    Y_raw = np.array(df['LABEL']).reshape((len(df['LABEL']), 1))\n",
    "    Y = Y_raw == 2\n",
    "    return X, Y\n",
    "\n",
    "# Function to train and evaluate SVM models with different kernels\n",
    "def train_and_evaluate_kernel(X_train, Y_train, X_dev, Y_dev, kernels=['linear', 'rbf', 'poly']):\n",
    "    results = []\n",
    "\n",
    "    # Loop through the kernels\n",
    "    for kernel in kernels:\n",
    "        print(f\"Training SVM with {kernel} kernel...\")\n",
    "\n",
    "        # Initialize the SVM model with the corresponding kernel\n",
    "        if kernel == 'poly':\n",
    "            model = SVC(kernel=kernel, degree=4)  # Polynomial kernel with degree 4\n",
    "        else:\n",
    "            model = SVC(kernel=kernel)  # Linear or Gaussian (RBF) kernel\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, Y_train.ravel())  # Flatten Y_train to avoid warning\n",
    "\n",
    "        # Make predictions\n",
    "        train_predictions = model.predict(X_train)\n",
    "        dev_predictions = model.predict(X_dev)\n",
    "\n",
    "        # Calculate precision\n",
    "        precision_train = precision_score(Y_train, train_predictions)\n",
    "        precision_dev = precision_score(Y_dev, dev_predictions)\n",
    "\n",
    "        # Confusion matrices\n",
    "        confusion_train = confusion_matrix(Y_train, train_predictions)\n",
    "        confusion_dev = confusion_matrix(Y_dev, dev_predictions)\n",
    "\n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'kernel': kernel,\n",
    "            'precision_train': precision_train,\n",
    "            'precision_dev': precision_dev,\n",
    "            'confusion_train': confusion_train,\n",
    "            'confusion_dev': confusion_dev\n",
    "        })\n",
    "        \n",
    "        # Display results for the current kernel\n",
    "        print(f\"Kernel: {kernel}\")\n",
    "        print(f\"Train Precision: {precision_train}\")\n",
    "        print(f\"Dev Precision: {precision_dev}\")\n",
    "        print(f\"Confusion Matrix (Train):\\n{confusion_train}\")\n",
    "        print(f\"Confusion Matrix (Dev):\\n{confusion_dev}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Load the data\n",
    "root_dir = \"/documents/kepler-20241219T145340Z-001/kepler/data_injected/\"\n",
    "train_dataset_path = os.path.join(root_dir, \"exoTrain.csv\")\n",
    "dev_dataset_path = os.path.join(root_dir, \"exoTest.csv\")\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "df_train = pd.read_csv(train_dataset_path, encoding=\"ISO-8859-1\")\n",
    "df_dev = pd.read_csv(dev_dataset_path, encoding=\"ISO-8859-1\")\n",
    "print(\"Loaded datasets!\")\n",
    "\n",
    "# Generate X and Y dataframes\n",
    "df_train_x = df_train.drop('LABEL', axis=1)\n",
    "df_dev_x = df_dev.drop('LABEL', axis=1)\n",
    "df_train_y = df_train.LABEL\n",
    "df_dev_y = df_dev.LABEL\n",
    "\n",
    "# Preprocess the data\n",
    "LFP = LightFluxProcessor(\n",
    "    fourier=True,\n",
    "    normalize=True,\n",
    "    gaussian=True,\n",
    "    standardize=True)\n",
    "df_train_x, df_dev_x = LFP.process(df_train_x, df_dev_x)\n",
    "\n",
    "# Rejoin X and Y dataframes\n",
    "df_train_processed = pd.DataFrame(df_train_x).join(pd.DataFrame(df_train_y))\n",
    "df_dev_processed = pd.DataFrame(df_dev_x).join(pd.DataFrame(df_dev_y))\n",
    "\n",
    "# Convert dataframes to numpy arrays\n",
    "X_train, Y_train = np_X_Y_from_df(df_train_processed)\n",
    "X_dev, Y_dev = np_X_Y_from_df(df_dev_processed)\n",
    "\n",
    "# Train and evaluate SVM models with different kernels\n",
    "results = train_and_evaluate_kernel(X_train, Y_train, X_dev, Y_dev)\n",
    "\n",
    "# Save the results to a text file\n",
    "with open(\"report_injection_assignment2_taskE.txt\", \"w\") as f:\n",
    "    for result in results:\n",
    "        f.write(f\"Kernel: {result['kernel']}\\n\")\n",
    "        f.write(f\"Train Precision: {result['precision_train']}\\n\")\n",
    "        f.write(f\"Dev Precision: {result['precision_dev']}\\n\")\n",
    "        f.write(f\"Confusion Matrix (Train):\\n{result['confusion_train']}\\n\")\n",
    "        f.write(f\"Confusion Matrix (Dev):\\n{result['confusion_dev']}\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21883668-559c-42fc-9c37-fe0b3469a794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
